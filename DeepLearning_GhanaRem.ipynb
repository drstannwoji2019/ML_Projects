{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXOWiVWFpG9ayKepGMIsSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drstannwoji2019/ML_Projects/blob/main/DeepLearning_GhanaRem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Load Dataset\n",
        "file_path = \"/Remittances_Ghana.csv\"  # Update with correct file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert 'Date' column to datetime and set as index\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%Y')\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "# Normalize the target variable\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df_scaled = scaler.fit_transform(df[['Rem_Ghana']])\n",
        "\n",
        "# Split into training and testing sets (80% train, 20% test)\n",
        "train_size = int(len(df_scaled) * 0.8)\n",
        "train_data, test_data = df_scaled[:train_size], df_scaled[train_size:]\n",
        "\n",
        "# Function to create sequences for time series forecasting\n",
        "def create_sequences(data, time_step=3):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        X.append(data[i:(i + time_step)])\n",
        "        y.append(data[i + time_step])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Define lookback window\n",
        "time_step = 3\n",
        "X_train, y_train = create_sequences(train_data, time_step)\n",
        "X_test, y_test = create_sequences(test_data, time_step)\n",
        "\n",
        "# Reshape data for deep learning models\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Function to build and train a model\n",
        "def build_and_train_model(model_type, X_train, y_train, X_test, y_test, epochs=100, batch_size=1):\n",
        "    model = Sequential()\n",
        "    if model_type == \"RNN\":\n",
        "        model.add(SimpleRNN(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    elif model_type == \"LSTM\":\n",
        "        model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    elif model_type == \"GRU\":\n",
        "        model.add(GRU(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # Predict on test data\n",
        "    predictions = model.predict(X_test)\n",
        "    return model, predictions\n",
        "\n",
        "# Train RNN, LSTM, and GRU models\n",
        "rnn_model, rnn_predictions = build_and_train_model(\"RNN\", X_train, y_train, X_test, y_test)\n",
        "lstm_model, lstm_predictions = build_and_train_model(\"LSTM\", X_train, y_train, X_test, y_test)\n",
        "gru_model, gru_predictions = build_and_train_model(\"GRU\", X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Inverse transform predictions to original scale\n",
        "rnn_predictions = scaler.inverse_transform(rnn_predictions)\n",
        "lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
        "gru_predictions = scaler.inverse_transform(gru_predictions)\n",
        "\n",
        "# Inverse transform actual values\n",
        "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return mae, rmse\n",
        "\n",
        "# Evaluate models\n",
        "rnn_mae, rnn_rmse = evaluate_model(y_test_actual, rnn_predictions)\n",
        "lstm_mae, lstm_rmse = evaluate_model(y_test_actual, lstm_predictions)\n",
        "gru_mae, gru_rmse = evaluate_model(y_test_actual, gru_predictions)\n",
        "\n",
        "# Print results\n",
        "print(f\"RNN - MAE: {rnn_mae:.2f}, RMSE: {rnn_rmse:.2f}\")\n",
        "print(f\"LSTM - MAE: {lstm_mae:.2f}, RMSE: {lstm_rmse:.2f}\")\n",
        "print(f\"GRU - MAE: {gru_mae:.2f}, RMSE: {gru_rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "degdjwzTg2Wd",
        "outputId": "5b5a6df4-cf52-4fa1-f4e9-3e3c58991dde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
            "RNN - MAE: 581871593.00, RMSE: 581871593.00\n",
            "LSTM - MAE: 866617065.00, RMSE: 866617065.00\n",
            "GRU - MAE: 875107561.00, RMSE: 875107561.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to store and display the results\n",
        "metrics_data = {\n",
        "    \"Model\": [\"RNN\", \"LSTM\", \"GRU\"],\n",
        "    \"MAE\": [rnn_mae, lstm_mae, gru_mae],\n",
        "    \"RMSE\": [rnn_rmse, lstm_rmse, gru_rmse]\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Print the table\n",
        "print(metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hed_CjxMiLvl",
        "outputId": "19e502fa-5691-4d77-efe6-f78125fe9663"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Model          MAE         RMSE\n",
            "0   RNN  581871593.0  581871593.0\n",
            "1  LSTM  866617065.0  866617065.0\n",
            "2   GRU  875107561.0  875107561.0\n"
          ]
        }
      ]
    }
  ]
}